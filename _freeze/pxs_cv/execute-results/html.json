{
  "hash": "d6fbc9d41fc6c300a0d9332c7e6bba3d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"CroosValidation Logistic Regression and Machine Learning Models for Predicting Stock Market Movements in the Pakistan Stock Exchange (PSX)\"\ntitle-banner-block: true\nauthor: \"Prof. Dr. Zahid Asghar\"\nformat: html\nexecute:\n  freeze: auto\n  warnings: false\n  message: false\neditor_options: \n  chunk_output_type: console\n---\n\n### Tidied Code with Confusion Matrix and Improvements\n\n---\n\n#### Libraries and Setup\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(caret)      # For model evaluation and cross-validation\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: ggplot2\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: lattice\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'lattice' was built under R version 4.5.1\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(rpart)      # For Decision Trees\nlibrary(tidyverse)  # For data manipulation and visualization\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'tidyverse' was built under R version 4.5.1\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'purrr' was built under R version 4.5.1\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.4     ✔ tibble    3.3.0\n✔ purrr     1.1.0     ✔ tidyr     1.3.1\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n✖ purrr::lift()   masks caret::lift()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(Metrics)    # For additional evaluation metrics\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'Metrics' was built under R version 4.5.1\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'Metrics'\n\nThe following objects are masked from 'package:caret':\n\n    precision, recall\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(janitor)    # For cleaning column names\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'janitor'\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(MASS)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'MASS'\n\nThe following object is masked from 'package:dplyr':\n\n    select\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(class)      # For KNN\nlibrary(boot)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'boot' was built under R version 4.5.1\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'boot'\n\nThe following object is masked from 'package:lattice':\n\n    melanoma\n```\n\n\n:::\n:::\n\n\n---\n\n#### Load and Inspect Data\n\n::: {.cell}\n\n```{.r .cell-code}\npsx <- read_csv(\"data/psx.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 1827 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): Date, Vol., Change %\ndbl (4): Price, Open, High, Low\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\n# Inspect the structure of the dataset\ndim(psx)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1827    7\n```\n\n\n:::\n\n```{.r .cell-code}\nglimpse(psx)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 1,827\nColumns: 7\n$ Date       <chr> \"11/15/2024\", \"11/14/2024\", \"11/13/2024\", \"11/12/2024\", \"11…\n$ Price      <dbl> 17.42, 17.19, 16.78, 16.86, 17.02, 17.22, 17.14, 17.31, 16.…\n$ Open       <dbl> 17.40, 16.70, 16.95, 17.00, 17.46, 17.14, 17.24, 17.24, 17.…\n$ High       <dbl> 17.60, 17.60, 16.95, 17.20, 17.46, 17.49, 17.60, 17.50, 17.…\n$ Low        <dbl> 16.90, 16.55, 16.50, 16.70, 16.97, 17.01, 17.00, 16.60, 16.…\n$ Vol.       <chr> \"896.83K\", \"1.01M\", \"239.44K\", \"179.95K\", \"364.92K\", \"208.0…\n$ `Change %` <chr> \"1.34%\", \"2.44%\", \"-0.47%\", \"-0.94%\", \"-1.16%\", \"0.47%\", \"-…\n```\n\n\n:::\n:::\n\n\n---\n\n#### Data Cleaning and Feature Engineering\n\n::: {.cell}\n\n```{.r .cell-code}\n# Convert the `Date` column to proper Date format and clean column names\npsx <- psx %>%\n  mutate(date = as.Date(Date, format = \"%m/%d/%Y\")) %>%\n  dplyr::select(-Date) %>%\n  clean_names()\n\n# Create `change_percent` as numeric and a binary `direction` column\npsx <- psx %>%\n  mutate(\n    change_percent = as.numeric(str_remove(change_percent, \"%\")),\n    direction = if_else(change_percent > 0, \"Up\", \"Down\")\n  )\n\n# Arrange by ascending date\npsx <- psx %>% arrange(date)\n\n# Generate lag variables and convert `vol` to numeric (account for M/K suffixes)\npsx <- psx %>%\n  mutate(\n    lag1 = lag(change_percent, 1),\n    lag2 = lag(change_percent, 2),\n    lag3 = lag(change_percent, 3),\n    lag4 = lag(change_percent, 4),\n    lag5 = lag(change_percent, 5),\n    vol = as.numeric(str_replace_all(vol, c(\"M\" = \"e6\", \"K\" = \"e3\")))\n  )\n\n# Drop rows with missing values\npsx_clean <- psx %>% drop_na()\n\n# Convert `direction` to a factor for classification\npsx_clean <- psx_clean %>%\n  mutate(direction = factor(if_else(direction == \"Up\", 1, 0), levels = c(0, 1), labels = c(\"Down\", \"Up\")))\n```\n:::\n\n\n---\n\n#### Cross-Validation with Logistic Regression\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define custom summary function to include confusion matrix and accuracy\nlogistic_summary <- function(data, lev = NULL, model = NULL) {\n  confusion <- confusionMatrix(data$pred, data$obs)\n  out <- c(Accuracy = confusion$overall[\"Accuracy\"])\n  return(out)\n}\n\n# Define trainControl for different cross-validation methods\ntrain_control_loocv <- trainControl(method = \"LOOCV\", summaryFunction = logistic_summary, classProbs = TRUE)\ntrain_control_5fold <- trainControl(method = \"cv\", number = 5, summaryFunction = logistic_summary, classProbs = TRUE)\ntrain_control_10fold <- trainControl(method = \"cv\", number = 10, summaryFunction = logistic_summary, classProbs = TRUE)\n\n# Train logistic regression models\nset.seed(123)\nmodel_loocv <- train(\n  direction ~ lag1 + lag2 + lag3 + lag4 + lag5 + vol,\n  data = psx_clean,\n  method = \"glm\",\n  family = binomial,\n  trControl = train_control_loocv,\n  metric = \"Accuracy\"\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in train.default(x, y, weights = w, ...): The metric \"Accuracy\" was not\nin the result set. Accuracy.Accuracy will be used instead.\n```\n\n\n:::\n\n```{.r .cell-code}\nmodel_5fold <- train(\n  direction ~ lag1 + lag2 + lag3 + lag4 + lag5 + vol,\n  data = psx_clean,\n  method = \"glm\",\n  family = binomial,\n  trControl = train_control_5fold,\n  metric = \"Accuracy\"\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in train.default(x, y, weights = w, ...): The metric \"Accuracy\" was not\nin the result set. Accuracy.Accuracy will be used instead.\n```\n\n\n:::\n\n```{.r .cell-code}\nmodel_10fold <- train(\n  direction ~ lag1 + lag2 + lag3 + lag4 + lag5 + vol,\n  data = psx_clean,\n  method = \"glm\",\n  family = binomial,\n  trControl = train_control_10fold,\n  metric = \"Accuracy\"\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in train.default(x, y, weights = w, ...): The metric \"Accuracy\" was not\nin the result set. Accuracy.Accuracy will be used instead.\n```\n\n\n:::\n:::\n\n\n---\n\n#### Extract Training Results\n\n::: {.cell}\n\n```{.r .cell-code}\n# Combine cross-validation results into a summary data frame\nresults_train <- data.frame(\n  Method = c(\"LOOCV\", \"5-Fold CV\", \"10-Fold CV\"),\n  Training_Accuracy = c(\n    model_loocv$results$Accuracy[1],\n    model_5fold$results$Accuracy[1],\n    model_10fold$results$Accuracy[1]\n  )\n)\n\nprint(results_train)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      Method Training_Accuracy\n1      LOOCV         0.6108672\n2  5-Fold CV         0.6108672\n3 10-Fold CV         0.6108672\n```\n\n\n:::\n:::\n\n\n---\n\n#### Train-Test Split and Testing Accuracy\n\n::: {.cell}\n\n```{.r .cell-code}\n# Train-test split based on date\ntrain_data <- psx_clean %>% filter(date < as.Date(\"2024-01-01\"))\ntest_data <- psx_clean %>% filter(date >= as.Date(\"2024-01-01\"))\n\n# Predictions and accuracy on the test set\nloocv_preds <- predict(model_loocv, newdata = test_data)\nloocv_test_accuracy <- mean(loocv_preds == test_data$direction)\n\nfold5_preds <- predict(model_5fold, newdata = test_data)\nfold5_test_accuracy <- mean(fold5_preds == test_data$direction)\n\nfold10_preds <- predict(model_10fold, newdata = test_data)\nfold10_test_accuracy <- mean(fold10_preds == test_data$direction)\n\n# Summarize training and testing accuracies\nresults <- data.frame(\n  Method = c(\"LOOCV\", \"5-Fold CV\", \"10-Fold CV\"),\n  Training_Accuracy = results_train$Training_Accuracy,\n  Test_Accuracy = c(loocv_test_accuracy, fold5_test_accuracy, fold10_test_accuracy)\n)\n\nprint(results)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      Method Training_Accuracy Test_Accuracy\n1      LOOCV         0.6108672     0.6232558\n2  5-Fold CV         0.6108672     0.6232558\n3 10-Fold CV         0.6108672     0.6232558\n```\n\n\n:::\n:::\n\n\n---\n\n#### Confusion Matrix for Test Set Predictions\n\n::: {.cell}\n\n```{.r .cell-code}\n# Confusion matrices for the test set\nconfusionMatrix(data = loocv_preds, reference = test_data$direction, positive = \"Up\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction Down Up\n      Down   77 43\n      Up     38 57\n                                          \n               Accuracy : 0.6233          \n                 95% CI : (0.5548, 0.6882)\n    No Information Rate : 0.5349          \n    P-Value [Acc > NIR] : 0.005484        \n                                          \n                  Kappa : 0.2403          \n                                          \n Mcnemar's Test P-Value : 0.656721        \n                                          \n            Sensitivity : 0.5700          \n            Specificity : 0.6696          \n         Pos Pred Value : 0.6000          \n         Neg Pred Value : 0.6417          \n             Prevalence : 0.4651          \n         Detection Rate : 0.2651          \n   Detection Prevalence : 0.4419          \n      Balanced Accuracy : 0.6198          \n                                          \n       'Positive' Class : Up              \n                                          \n```\n\n\n:::\n\n```{.r .cell-code}\nconfusionMatrix(data = fold5_preds, reference = test_data$direction, positive = \"Up\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction Down Up\n      Down   77 43\n      Up     38 57\n                                          \n               Accuracy : 0.6233          \n                 95% CI : (0.5548, 0.6882)\n    No Information Rate : 0.5349          \n    P-Value [Acc > NIR] : 0.005484        \n                                          \n                  Kappa : 0.2403          \n                                          \n Mcnemar's Test P-Value : 0.656721        \n                                          \n            Sensitivity : 0.5700          \n            Specificity : 0.6696          \n         Pos Pred Value : 0.6000          \n         Neg Pred Value : 0.6417          \n             Prevalence : 0.4651          \n         Detection Rate : 0.2651          \n   Detection Prevalence : 0.4419          \n      Balanced Accuracy : 0.6198          \n                                          \n       'Positive' Class : Up              \n                                          \n```\n\n\n:::\n\n```{.r .cell-code}\nconfusionMatrix(data = fold10_preds, reference = test_data$direction, positive = \"Up\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction Down Up\n      Down   77 43\n      Up     38 57\n                                          \n               Accuracy : 0.6233          \n                 95% CI : (0.5548, 0.6882)\n    No Information Rate : 0.5349          \n    P-Value [Acc > NIR] : 0.005484        \n                                          \n                  Kappa : 0.2403          \n                                          \n Mcnemar's Test P-Value : 0.656721        \n                                          \n            Sensitivity : 0.5700          \n            Specificity : 0.6696          \n         Pos Pred Value : 0.6000          \n         Neg Pred Value : 0.6417          \n             Prevalence : 0.4651          \n         Detection Rate : 0.2651          \n   Detection Prevalence : 0.4419          \n      Balanced Accuracy : 0.6198          \n                                          \n       'Positive' Class : Up              \n                                          \n```\n\n\n:::\n:::\n\n\n---\n\n### Key Adjustments\n1. **Added Confusion Matrices**: Included confusion matrices for test set predictions to provide more insights into model performance.\n2. **Tidied Formatting**: Improved indentation, consistency, and readability of the code.\n3. **Combined Results**: Created a single data frame summarizing both training and testing accuracies for all cross-validation methods.\n4. **Test Accuracy Evaluation**: Added predictions on the test set to complement training accuracy metrics.\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}